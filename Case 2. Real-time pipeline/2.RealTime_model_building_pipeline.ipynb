{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Model Building Pipelines\n",
    "\n",
    "## Runtime\n",
    "\n",
    "This notebook takes approximately an half hour to run.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [A SageMaker Pipeline](#A-SageMaker-Pipeline)\n",
    "1. [Define Parameters to Parametrize Pipeline Execution](#Define-Parameters-to-Parametrize-Pipeline-Execution)\n",
    "1. [Define a Cache](#Define-a-Cache)\n",
    "1. [Define a Processing Step for Feature Engineering](#Define-a-Processing-Step-for-Feature-Engineering)\n",
    "1. [Define a Training Step to Train a Model](#Define-a-Training-Step-to-Train-a-Model)\n",
    "1. [Define a Model Evaluation Step to Evaluate the Trained Model](#Define-a-Model-Evaluation-Step-to-Evaluate-the-Trained-Model)\n",
    "1. [Define a Register Model Step to Create a Model Package](#Define-a-Register-Model-Step-to-Create-a-Model-Package)\n",
    "1. [Define a Lambda Step to deploy endpoint](#Define-a-Lambda-Step-to-deploy-endpoint)\n",
    "1. [Define a Fail Step to Terminate the Pipeline Execution and Mark it as Failed](#Define-a-Fail-Step-to-Terminate-the-Pipeline-Execution-and-Mark-it-as-Failed)\n",
    "1. [Define a Condition Step to Check Accuracy and Conditionally Create a Model and Run a Batch Transformation and Register a Model in the Model Registry, Or Terminate the Execution in Failed State](#Define-a-Condition-Step-to-Check-Accuracy-and-Conditionally-Create-a-Model-and-Run-a-Batch-Transformation-and-Register-a-Model-in-the-Model-Registry,-Or-Terminate-the-Execution-in-Failed-State)\n",
    "1. [Define a Pipeline of Parameters, Steps, and Conditions](#Define-a-Pipeline-of-Parameters,-Steps,-and-Conditions)\n",
    "1. [Submit the pipeline to SageMaker and start execution](#Submit-the-pipeline-to-SageMaker-and-start-execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A SageMaker Pipeline\n",
    "\n",
    "생성하는 파이프라인은 사전 처리, 교육, 평가, 모델 생성 및 모델 등록의 일반적인 기계 학습(ML) 애플리케이션 패턴을 따릅니다:\n",
    "\n",
    "![Model building pipeline](img/pipeline-full.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "nick_name = 'NickName'  # 다음에서 실습할 리소스명을 변경해주세요.\n",
    "\n",
    "# 여러명 동시 작업을 위해 다음 변수 커스터마이징\n",
    "pipeline_name = f\"{nick_name}-Realtime-Pipeline\" # 다음에서 실습할 파이프라인명을 변경해주세요.\n",
    "model_package_group_name = f\"{nick_name}-PackageGroupName\" # 모델 레지스트리에 등록될 package group name을 변경해주세요.\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "# default_bucket = sagemaker_session.default_bucket()\n",
    "default_bucket = 'sagemake-pipeline-workshop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 기본 버킷에 데이터를 업로드합니다. 'input_data_uri'에 대한 자체 데이터 세트 경로를 입력할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"data/abalone-dataset.csv\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3.Bucket(f\"sagemaker-sample-files\").download_file(\n",
    "    \"datasets/tabular/uci_abalone/abalone.csv\", local_path\n",
    ")\n",
    "\n",
    "base_uri = f\"s3://{default_bucket}/abalone\"\n",
    "input_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=local_path,\n",
    "    desired_s3_uri=base_uri,\n",
    ")\n",
    "print(input_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 생성 후 일괄 변환을 위한 두 번째 데이터 세트를 다운로드합니다. 적절하게 `batch_data_uri`에 대한 자체 데이터 세트 경로를 입력할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"data/abalone-dataset-batch\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3.Bucket(f\"sagemaker-servicecatalog-seedcode-{region}\").download_file(\n",
    "    \"dataset/abalone-dataset-batch\", local_path\n",
    ")\n",
    "\n",
    "base_uri = f\"s3://{default_bucket}/abalone\"\n",
    "batch_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=local_path,\n",
    "    desired_s3_uri=base_uri,\n",
    ")\n",
    "print(batch_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters to Parametrize Pipeline Execution\n",
    "\n",
    "파이프라인을 매개변수화하는데 사용할 수 있는 파이프라인 매개변수를 정의합니다. 매개변수를 사용하면 파이프라인 정의를 수정하지 않고도 사용자 지정 파이프라인 실행 및 일정을 사용할 수 있습니다.\n",
    "\n",
    "The supported parameter types include:\n",
    "\n",
    "* `ParameterString` - represents a `str` Python type\n",
    "* `ParameterInteger` - represents an `int` Python type\n",
    "* `ParameterFloat` - represents a `float` Python type\n",
    "\n",
    "이러한 매개변수는 파이프라인 실행 시 재정의할 수 있는 기본값 제공을 지원합니다. 지정된 기본값은 매개변수 유형과 동일한 타입이어야 합니다.\n",
    "\n",
    "The parameters defined in this workflow include:\n",
    "\n",
    "* `processing_instance_type` - 처리 작업의 `ml.*` 인스턴스 유형.\n",
    "* `processing_instance_count` - 처리 작업의 인스턴스 수입니다.\n",
    "* `instance_type` - 학습 작업의 `ml.*` 인스턴스 유형입니다.\n",
    "* `model_approval_status` - CI/CD 목적으로 훈련된 모델에 등록하기 위한 승인 상태입니다(기본값은 \"Approved\").\n",
    "* `input_data` - 입력 데이터의 S3 버킷 URI 위치입니다.\n",
    "* `batch_data` - 배치 데이터의 S3 버킷 URI 위치입니다.\n",
    "* `mse_threshold` - 모델의 정확도를 확인하는 데 사용되는 MSE(평균 제곱 오차) 임계값입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    ")\n",
    "\n",
    "\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.m5.large\"\n",
    ")\n",
    "instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m5.large\")\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"Approved\"\n",
    ")\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=input_data_uri,\n",
    ")\n",
    "batch_data = ParameterString(\n",
    "    name=\"BatchData\",\n",
    "    default_value=batch_data_uri,\n",
    ")\n",
    "mse_threshold = ParameterFloat(name=\"MseThreshold\", default_value=6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Cache\n",
    "- 참고: 캐싱 파이프라인 단계:  [Caching Pipeline Steps](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/pipelines-caching.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import CacheConfig\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, \n",
    "                           expire_after=\"7d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define Parameters](img/pipeline-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Processing Step for Feature Engineering\n",
    "\n",
    "먼저 처리 단계에서 지정한 전처리 스크립트를 개발합니다.\n",
    "\n",
    "이 노트북 셀은 전처리 스크립트가 포함된 `preprocessing_abalone.py` 파일을 작성합니다. 스크립트를 업데이트하고 이 셀을 다시 실행하여 덮어쓸 수 있습니다. 전처리 스크립트는 `scikit-learn`을 사용하여 다음을 수행합니다.\n",
    "\n",
    "* 누락된 성별 카테고리 데이터를 채우고 훈련에 적합하도록 인코딩합니다.\n",
    "* 성별 및 고리 숫자 데이터를 제외한 모든 숫자 필드를 확장하고 정규화합니다.\n",
    "* 데이터를 훈련, 검증 및 테스트 데이터 세트로 분할합니다.\n",
    "\n",
    "처리 단계는 입력 데이터에 대한 스크립트를 실행합니다. 교육 단계에서는 사전 처리된 교육 기능과 레이블을 사용하여 모델을 교육합니다. 평가 단계에서는 훈련된 모델과 사전 처리된 테스트 기능 및 레이블을 사용하여 모델을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile abalone/preprocessing.py\n",
    "import argparse\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "# Since we get a headerless CSV file, we specify the column names here.\n",
    "feature_columns_names = [\n",
    "    \"sex\",\n",
    "    \"length\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"whole_weight\",\n",
    "    \"shucked_weight\",\n",
    "    \"viscera_weight\",\n",
    "    \"shell_weight\",\n",
    "]\n",
    "label_column = \"rings\"\n",
    "\n",
    "feature_columns_dtype = {\n",
    "    \"sex\": str,\n",
    "    \"length\": np.float64,\n",
    "    \"diameter\": np.float64,\n",
    "    \"height\": np.float64,\n",
    "    \"whole_weight\": np.float64,\n",
    "    \"shucked_weight\": np.float64,\n",
    "    \"viscera_weight\": np.float64,\n",
    "    \"shell_weight\": np.float64,\n",
    "}\n",
    "label_column_dtype = {\"rings\": np.float64}\n",
    "\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        f\"{base_dir}/input/abalone-dataset.csv\",\n",
    "        header=None,\n",
    "        names=feature_columns_names + [label_column],\n",
    "        dtype=merge_two_dicts(feature_columns_dtype, label_column_dtype),\n",
    "    )\n",
    "    numeric_features = list(feature_columns_names)\n",
    "    numeric_features.remove(\"sex\")\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    "    )\n",
    "\n",
    "    categorical_features = [\"sex\"]\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    y = df.pop(\"rings\")\n",
    "    X_pre = preprocess.fit_transform(df)\n",
    "    y_pre = y.to_numpy().reshape(len(y), 1)\n",
    "\n",
    "    X = np.concatenate((y_pre, X_pre), axis=1)\n",
    "\n",
    "    np.random.shuffle(X)\n",
    "    train, validation, test = np.split(X, [int(0.7 * len(X)), int(0.85 * len(X))])\n",
    "\n",
    "    pd.DataFrame(train).to_csv(f\"{base_dir}/train/train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(\n",
    "        f\"{base_dir}/validation/validation.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(test).to_csv(f\"{base_dir}/test/test.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 `SKLearnProcessor` 프로세서의 인스턴스를 만들고 `ProcessingStep`에서 사용합니다.\n",
    "\n",
    "또한 이 노트북 전체에서 사용할 'framework_version'을 지정합니다.\n",
    "\n",
    "프로세서 인스턴스에서 사용하는 'processing_instance_type' 및 'processing_instance_count' 매개변수에 유의하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-abalone-process\",\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 프로세서 인스턴스를 사용하여 입력 및 출력 채널, 파이프라인이 파이프라인 실행을 호출할 때 실행되는 코드와 함께 `ProcessingStep`을 구성합니다. 이는 Python SDK에서 프로세서 인스턴스의 'run()' 메서드와 유사합니다.\n",
    "\n",
    "`ProcessingStep`에 전달된 `input_data` 매개변수는 단계에서 사용되는 입력 데이터입니다. 이 입력 데이터는 프로세서 인스턴스가 실행될 때 사용됩니다.\n",
    "\n",
    "또한 처리 작업에 대한 출력 구성에 지정된 `\"train_data\"` 및 `\"test_data\"` 이름의 채널에 유의하십시오. '속성' 단계는 후속 단계에서 사용할 수 있으며 실행 시 런타임 값으로 확인할 수 있습니다. 특히, 이 사용법은 훈련 단계를 정의할 때 호출됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"AbaloneProcess\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"abalone/preprocessing.py\",\n",
    "    cache_config = cache_config, # 캐시 정의\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Processing Step for Feature Engineering](img/pipeline-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Training Step to Train a Model\n",
    "\n",
    "이 섹션에서는 Amazon SageMaker의 [XGBoost Algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html)을 사용하여 이 데이터 세트를 교육합니다. XGBoost 알고리즘 및 입력 데이터 세트에 대한 Estimator를 구성합니다. 일반적인 훈련 스크립트는 입력 채널에서 데이터를 로드하고, 하이퍼파라미터로 훈련을 구성하고, 모델을 훈련하고, 나중에 호스팅할 수 있도록 모델을 `model_dir`에 저장합니다.\n",
    "\n",
    "훈련의 모델이 저장되는 모델 경로도 지정됩니다.\n",
    "\n",
    "'instance_type' 매개변수는 파이프라인의 여러 위치에서 사용될 수 있습니다. 이 경우 'instance_type'이 estimator로 전달됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "\n",
    "model_path = f\"s3://{default_bucket}/AbaloneTrain\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.0-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=instance_type,\n",
    ")\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=model_path,\n",
    "    role=role,\n",
    "    disable_profiler=True      \n",
    ")\n",
    "xgb_train.set_hyperparameters(\n",
    "    objective=\"reg:linear\",\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 estimator 인스턴스를 사용하여 `TrainingStep` 입력과 파이프라인이 파이프라인 실행을 호출할 때 실행되는 코드에서 입력으로 사용된 이전 `ProcessingStep`의 `properties`와 `TrainingStep`을 구성합니다. 이것은 Python SDK의 estimator의 'fit' 방법과 유사합니다.\n",
    "\n",
    "`\"train_data\"` 출력 채널의 `S3Uri`를 `TrainingStep`에 전달합니다. 또한 파이프라인에서 모델 평가를 위해 다른 `\"test_data\"` 출력 채널을 사용합니다. 파이프라인 단계의 'properties' 속성은 설명 호출에 대한 해당 응답의 개체 모델과 일치합니다. 이러한 속성은 자리 표시자 값으로 참조될 수 있으며 런타임에 확인됩니다. 예를 들어 `ProcessingStep` `properties` 속성은 [DescribeProcessingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeProcessingJob.html) 응답 객체의 객체 모델과 일치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"AbaloneTrain\",\n",
    "    estimator=xgb_train,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    "    cache_config = cache_config, # 캐시 정의\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Training Step to Train a Model](img/pipeline-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Model Evaluation Step to Evaluate the Trained Model\n",
    "\n",
    "먼저 모델 평가를 수행하는 처리 단계에서 지정된 평가 스크립트를 개발합니다.\n",
    "\n",
    "파이프라인 실행 후 분석을 위해 결과 'evaluation.json'을 검사할 수 있습니다.\n",
    "\n",
    "평가 스크립트는 `xgboost`를 사용하여 다음을 수행합니다.\n",
    "\n",
    "* 모델을 로드합니다.\n",
    "* 테스트 데이터를 읽습니다.\n",
    "* 테스트 데이터에 대한 예측을 발행합니다.\n",
    "* 정확도 및 ROC 곡선을 포함하는 분류 보고서를 작성합니다.\n",
    "* 평가 보고서를 평가 디렉토리에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile abalone/evaluation.py\n",
    "import json\n",
    "import pathlib\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = f\"/opt/ml/processing/model/model.tar.gz\"\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\".\")\n",
    "\n",
    "    model = pickle.load(open(\"xgboost-model\", \"rb\"))\n",
    "\n",
    "    test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "    df = pd.read_csv(test_path, header=None)\n",
    "\n",
    "    y_test = df.iloc[:, 0].to_numpy()\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "    X_test = xgboost.DMatrix(df.values)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    std = np.std(y_test - predictions)\n",
    "    report_dict = {\n",
    "        \"regression_metrics\": {\n",
    "            \"mse\": {\"value\": mse, \"standard_deviation\": std},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 `ScriptProcessor` 프로세서의 인스턴스를 만들고 `ProcessingStep`에서 사용합니다.\n",
    "\n",
    "프로세서에 전달된 `processing_instance_type` 매개변수에 유의하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"script-abalone-eval\",\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프로세서 인스턴스를 사용하여 입력 및 출력 채널과 파이프라인이 파이프라인 실행을 호출할 때 실행되는 코드와 함께 `ProcessingStep`을 구성합니다. 이는 Python SDK에서 프로세서 인스턴스의 'run' 메서드와 유사합니다.\n",
    "\n",
    "특히, `step_train` `properties`의 `S3ModelArtifacts`와 `step_process` `properties`의 `\"test_data\"` output channel의 `S3Uri`이 입력으로 넘어갑니다. `TrainingStep`과 `ProcessingStep` `properties` 어트리뷰트는 각각 [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html)의 object model과 [DescribeProcessingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeProcessingJob.html) response objects로 매칭됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"AbaloneEval\",\n",
    "    processor=script_eval,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"abalone/evaluation.py\",\n",
    "    cache_config = cache_config, # 캐시 정의\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Model Evaluation Step to Evaluate the Trained Model](img/pipeline-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Register Model Step to Create a Model Package\n",
    "\n",
    "훈련 단계에서 지정된 estimator 인스턴스를 사용하여 `RegisterModel`의 인스턴스를 구성합니다. 파이프라인에서 'RegisterModel'을 실행한 결과는 모델 패키지입니다. 모델 패키지는 추론에 필요한 모든 구성 요소를 패키징하는 재사용 가능한 모델 아티팩트의 추상화입니다. 기본적으로 optional 모델 가중치 위치와 함께 사용할 추론 이미지를 정의하는 추론 사양으로 구성됩니다.\n",
    "\n",
    "모델 패키지 그룹은 모델 패키지의 모음입니다. 특정 ML 비즈니스 문제에 대해 모델 패키지 그룹을 생성할 수 있으며 여기에 모델 패키지의 새 버전을 추가할 수 있습니다. 일반적으로 고객은 모든 SageMaker 파이프라인 실행에 대해 모델 패키지 버전을 그룹에 추가할 수 있도록 SageMaker 파이프라인용 ModelPackageGroup을 생성해야 합니다.\n",
    "\n",
    "'RegisterModel'의 구성은 Python SDK의 estimator 인스턴스의 'register' 메서드와 유사합니다.\n",
    "\n",
    "특히 `TrainingStep`, `step_train` 속성에서 `S3ModelArtifacts`를 전달합니다. `TrainingStep` `properties` 속성은 [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) 응답 객체의 객체 모델과 일치합니다.\n",
    "\n",
    "이 노트북에 제공된 특정 모델 패키지 그룹 이름은 SageMaker 프로젝트와 함께 모델 레지스트리 및 CI/CD 작업에서 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "step_register = RegisterModel(\n",
    "    name=\"AbaloneRegisterModel\",\n",
    "    estimator=xgb_train,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Lambda Step and Create Model/Create Endpoint config/Create Endpoint](img/pipeline-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Lambda Step to deploy endpoint\n",
    "\n",
    "이 섹션에서는 다음 단계를 안내합니다:\n",
    "\n",
    "* Lambda Step을 활용하여 Sagemaker model/endpoint configuration/endpoint를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lambda_deployer.py\n",
    "\n",
    "\"\"\"\n",
    "This Lambda function creates an Endpoint Configuration and deploys a model to an Endpoint. \n",
    "The name of the model to deploy is provided via the `event` argument\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\" \"\"\"\n",
    "    sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "    # The name of the model created in the Pipeline CreateModelStep\n",
    "    model_name = event[\"model_name\"]\n",
    "    model_package_arn = event[\"model_package_arn\"]\n",
    "    endpoint_config_name = event[\"endpoint_config_name\"]\n",
    "    endpoint_name = event[\"endpoint_name\"]\n",
    "    role = event[\"role\"]\n",
    "    \n",
    "    container = {\"ModelPackageName\": model_package_arn}\n",
    "\n",
    "    create_model_respose = sm_client.create_model(ModelName=model_name, \n",
    "                                                  ExecutionRoleArn=role, \n",
    "                                                  Containers=[container] )\n",
    "\n",
    "    create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                \"InstanceType\": \"ml.m5.xlarge\",\n",
    "                \"InitialVariantWeight\": 1,\n",
    "                \"InitialInstanceCount\": 1,\n",
    "                \"ModelName\": model_name,\n",
    "                \"VariantName\": \"AllTraffic\",\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        create_endpoint_response = sm_client.create_endpoint(EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"update endpoint!!\")\n",
    "        \n",
    "        sm_client.update_endpoint(EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name)\n",
    "        \n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"body\": json.dumps(\"Created Endpoint!\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최초 한번만 실행\n",
    "\n",
    "import time\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "# Use the current time to define unique names for the resources created\n",
    "current_time = time.strftime(\"%m-%d-%H-%M-%S\", time.localtime())\n",
    "\n",
    "deploy_model_name = f'{nick_name}-abalone-model' + current_time\n",
    "endpoint_config_name = f\"{nick_name}-abalone-endpoint-config\" + current_time\n",
    "endpoint_name = f'{nick_name}-abalone-endpoint'\n",
    "function_name = f\"{nick_name}-sagemaker-abalone-lambda-step\"\n",
    "\n",
    "# Lambda helper class can be used to create the Lambda function\n",
    "func = Lambda(\n",
    "    function_name=function_name,\n",
    "    execution_role_arn=sagemaker.get_execution_role(),\n",
    "    script=\"lambda_deployer.py\",\n",
    "    handler=\"lambda_deployer.lambda_handler\",\n",
    "    timeout=600,\n",
    "    memory_size=3008\n",
    ")\n",
    "\n",
    "lambda_create_res = func.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_from_exist_lambda = Lambda(\n",
    "    function_arn=lambda_create_res['FunctionArn']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "\n",
    "# The dictionary retured by the Lambda function is captured by LambdaOutput, each key in the dictionary corresponds to a\n",
    "# LambdaOutput\n",
    "\n",
    "output_param_1 = LambdaOutput(output_name=\"statusCode\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_2 = LambdaOutput(output_name=\"body\", output_type=LambdaOutputTypeEnum.String)\n",
    "\n",
    "# The inputs provided to the Lambda function can be retrieved via the `event` object within the `lambda_handler` function\n",
    "# in the Lambda\n",
    "step_deploy_lambda = LambdaStep(\n",
    "    name=\"AbaloneDeploy\",\n",
    "    lambda_func=func_from_exist_lambda,\n",
    "    inputs={\n",
    "        \"model_name\": deploy_model_name,\n",
    "        \"endpoint_config_name\": endpoint_config_name,\n",
    "        \"endpoint_name\": endpoint_name,\n",
    "        \"model_package_arn\": step_register.steps[0].properties.ModelPackageArn,\n",
    "        \"role\": role,\n",
    "    },\n",
    "    cache_config=cache_config,\n",
    "    outputs=[output_param_1, output_param_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Fail Step to Terminate the Pipeline Execution and Mark it as Failed\n",
    "\n",
    "이 섹션에서는 다음 단계를 안내합니다:\n",
    "\n",
    "* 실행 실패의 원인을 나타내는 사용자 정의 오류 메시지와 함께 'FailStep'을 정의합니다.\n",
    "* 보다 유익한 오류 메시지를 작성하기 위해 동적 `mse_threshold` 매개변수가 있는 정적 텍스트 문자열을 추가하는 `Join` 기능으로 `FailStep` 오류 메시지를 입력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "step_fail = FailStep(\n",
    "    name=\"AbaloneMSEFail\",\n",
    "    error_message=Join(on=\" \", values=[\"Execution failed due to MSE >\", mse_threshold]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Fail Step to Terminate the Execution in Failed State](img/pipeline-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Condition Step to Check Accuracy and Conditionally Create a Model and Run a Batch Transformation and Register a Model in the Model Registry, Or Terminate the Execution in Failed State\n",
    "\n",
    "이 단계에서는 평가 단계 'step_eval'에 의해 결정된 모델의 정확도가 지정된 값을 초과한 경우에만 모델을 등록합니다. 그렇지 않으면 파이프라인 실행이 실패하고 종료됩니다. 'ConditionStep'을 사용하면 파이프라인이 단계 속성의 조건에 따라 파이프라인 DAG에서 조건부 실행을 지원할 수 있습니다.\n",
    "\n",
    "다음 섹션에서는 다음을 수행합니다:\n",
    "\n",
    "* 평가 단계 'step_eval'의 출력에서 ​​찾은 정확도 값에 'ConditionLessThanOrEqualTo'를 정의합니다.\n",
    "* `ConditionStep`의 조건 목록에 있는 조건을 사용합니다.\n",
    "* `CreateModelStep` 및 `TransformStep` 단계와 `RegisterModel` 단계 컬렉션을 `ConditionStep`의 `if_steps`에 전달합니다. 이는 조건이 `True`로 평가되는 경우에만 실행됩니다.\n",
    "* 조건이 'False'로 평가되는 경우에만 실행되는 'ConditionStep'의 'else_steps'에 'FailStep' 단계를 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"regression_metrics.mse.value\",\n",
    "    ),\n",
    "    right=mse_threshold,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"AbaloneMSECond\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register, step_deploy_lambda],\n",
    "    else_steps=[step_fail],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Condition Step to Check Accuracy and Conditionally Execute Steps](img/pipeline-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Pipeline of Parameters, Steps, and Conditions\n",
    "\n",
    "이 섹션에서는 실행할 수 있도록 단계를 파이프라인으로 결합합니다.\n",
    "\n",
    "파이프라인에는 '이름', '매개변수', '단계'가 필요합니다. 이름은 `(account, region)` 쌍 내에서 고유해야 합니다.\n",
    "\n",
    "메모:\n",
    "\n",
    "* 정의에 사용된 모든 매개변수가 있어야 합니다.\n",
    "* 파이프라인으로 전달된 단계는 실행 순서대로 나열할 필요가 없습니다. SageMaker 파이프라인 서비스는 실행을 완료하기 위한 단계로 데이터 종속성 DAG를 확인합니다.\n",
    "* 단계는 파이프라인 단계 목록과 모든 조건 단계 if/else 목록에서 고유해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "        batch_data,\n",
    "        mse_threshold,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_cond],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Pipeline of Parameters, Steps, and Conditions](img/pipeline-7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Examining the pipeline definition\n",
    "\n",
    "파이프라인 정의의 JSON을 검사하여 파이프라인이 잘 정의되어 있고 매개변수와 단계 속성이 올바르게 해석되는지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the pipeline to SageMaker and start execution\n",
    "\n",
    "파이프라인 정의를 파이프라인 서비스에 제출하십시오. 파이프라인 서비스는 전달된 역할을 사용하여 단계에서 정의된 모든 작업을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이프라인을 시작하고 모든 기본 매개변수를 accept합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Operations: Examining and Waiting for Pipeline Execution\n",
    "\n",
    "파이프라인 실행을 describe 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행이 완료될 때까지 기다리십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행 단계를 나열하십시오. 단계 실행기 서비스에서 해결한 파이프라인의 단계입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the endpoint\n",
    "\n",
    "파이프라인이 완료된 후 결과 모델 테스트를 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline definition 에서 test 데이터 uri를 찾아보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://sagemaker-ap-northeast-2-387402383014/AbaloneProcess-94160e00688e34972e58a18a33ec6342/output/test/test.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 3 test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payload for inference.\n",
    "payload = \"-99,-0.4496398881842701,-0.38175978348421347,-0.22754502585380668,-0.624562975084181,-0.7135715659196552,-0.43424377639795386,-0.5304474339068213,0.0,0.0,1.0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "endpoint_name = 'abalone-endpoint'                                     # Your endpoint name.\n",
    "content_type = \"text/csv\"                                        # The MIME type of the input data in the request body.\n",
    "accept = \"text/csv\"                                              # The desired MIME type of the inference in the response.\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType=content_type,\n",
    "    Accept=accept,\n",
    "    Body=payload\n",
    "    )\n",
    "\n",
    "print(response)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['Body'].read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearning Resources\n",
    "\n",
    "* lambda 삭제\n",
    "* !!! model / endpoint config / endpoint 삭제 (실행하지 말아주세요, 일괄 삭제하겠습니다)\n",
    "* pipeline 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.lambda_helper import Lambda\n",
    "func_from_exist_lambda = Lambda(\n",
    "    function_arn='arn:aws:lambda:ap-northeast-2:387402383014:function:sagemaker-abalone-lambda-step'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_from_exist_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda 삭제\n",
    "func_from_exist_lambda.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model / endpoint config / endpoint 삭제\n",
    "# sm_client = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model이 있는지 확인\n",
    "# response = sm_client.list_models(\n",
    "#     NameContains=f'{nick_name}-abalone-model',\n",
    "# )\n",
    "# model_names = [model_info['ModelName'] for model_info in response['Models']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델들 삭제\n",
    "# for model_name in model_names:\n",
    "#     sm_client.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## endpoint config 있는지 확인\n",
    "# response = sm_client.list_endpoint_configs(\n",
    "#     NameContains=f'{nick_name}-abalone-endpoint-config',\n",
    "# )\n",
    "\n",
    "# ep_config_names = [ep_config_info['EndpointConfigName'] for ep_config_info in response['EndpointConfigs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ep_config_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## endpoint_configs 삭제\n",
    "# for ep_config_name in ep_config_names:\n",
    "#     sm_client.delete_endpoint_config(EndpointConfigName=ep_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## endpoints 있는지 확인\n",
    "# response = sm_client.list_endpoints(\n",
    "#     NameContains=f'{nick_name}-abalone-endpoint',\n",
    "# )\n",
    "\n",
    "# ep_names = [ep_info['EndpointName'] for ep_info in response['Endpoints']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ep_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## endpoints 삭제\n",
    "# for ep_name in ep_names:\n",
    "#     sm_client.delete_endpoint(EndpointName=ep_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pipeline삭제\n",
    "\n",
    "import boto3\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "response = sm_client.describe_pipeline(\n",
    "            PipelineName= pipeline_name\n",
    "        )   \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_pipeline(PipelineName=pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
